---
index: 10
---

# Job System

This guide will walk you through creating jobs in Spacedrive's job system. The job system is designed to handle long-running tasks with features like progress tracking, pause/resume capabilities, and error handling.

## Job System Overview

The job system consists of several key components:

- **Job**: The high-level operation (e.g., file deletion, copying)
- **Tasks**: Individual units of work within a job
- **Behaviors**: Implementations of specific operations (e.g., different deletion strategies)
- **Progress Tracking**: System for monitoring and reporting job progress
- **State Management**: Handles job persistence and recovery
- **Undo Support**: Optional capability for jobs to define reversible operations
- **Location Handling**: Support for both location-bound and location-independent operations

## Creating a New Job

Let's walk through creating a job using the file deletion system as an example. The complete implementation can be found in `core/crates/file-actions/src/deleter/`.

### 0. Register the Job

Before implementing the job itself, you need to register it in two places:

1. Add it to the `JobName` enum in `job_system/job.rs`:

```rust
pub enum JobName {
    Indexer,
    FileIdentifier,
    MediaProcessor,
    Copy,
    Move,
    Delete,  // <-- Your new job name here
    // ...
}
```

2. Add your job's metadata type to `ReportInputMetadata` in `job_system/report.rs`:

```rust
pub enum ReportInputMetadata {
    // ... other jobs ...
    Deleter {
        location_id: location::id::Type,
        file_path_ids: Vec<file_path::id::Type>,
    },
    // Add your job's metadata here with the fields needed to track its progress
}
```

This registration is crucial for:

- Job identification in the system
- Progress tracking and reporting
- Job persistence and recovery
- UI display and management

### 1. Define Job Structure

First, create your job structure that will hold the necessary state:

```rust
#[derive(Debug)]
pub struct DeleterJob<B> {
    // Required parameters
    location_id: Option<location::id::Type>,
    file_path_ids: Vec<file_path::id::Type>,

    // Task management state
    pending_tasks: Option<Vec<TaskHandle<e>>>,
    shutdown_tasks: Option<Vec<Box<dyn Task<e>>>>,
    accumulative_errors: Option<Vec<e>>,

    // Generic behavior type
    behavior: PhantomData<fn(B) -> B>,
}
```

### 2. Define Job State

Create a serializable state structure for job persistence:

```rust
#[derive(Debug, Serialize, Deserialize)]
pub struct DeleterState {
    location_id: Option<location::id::Type>,
    file_path_ids: Vec<file_path::id::Type>,
    shutdown_tasks: Option<SerializedTasks>,
    accumulative_errors: Option<Vec<NonCriticalError>>,
}
```

### 3. Define Behavior Trait

If your job supports multiple implementations (like delete vs move to trash), create a behavior trait:

```rust
pub trait DeleteBehavior {
    fn delete(file: FileData) -> impl Future<Output = Result<ExecStatus, ()>> + Send;

    fn delete_all<I>(
        files: I,
        interrupter: Option<&Interrupter>,
    ) -> impl Future<Output = Result<ExecStatus, ()>> + Send
    where
        I: IntoIterator<Item = FileData> + Send + 'static,
        I::IntoIter: Send;
}
```

### 4. Implement Undo Support (Optional)

If your job needs to support undo operations, implement the `UndoableJob` trait:

```rust
impl UndoableJob for DeleterJob {
    fn create_undo_job(&self) -> Option<Box<dyn SerializableJob>> {
        // Create a job that will reverse the operation
        // For example, restore files from trash or recreate deleted directories
        Some(Box::new(RestoreJob {
            location_id: self.location_id,
            file_paths: self.file_paths.clone(),
        }))
    }
}
```

The undo job will be stored in the job history and can be executed later to reverse the operation.

### 5. Implement Behaviors

Create concrete implementations of your behavior:

```rust
// Permanent deletion behavior
pub struct RemoveBehavior;

impl DeleteBehavior for RemoveBehavior {
    async fn delete(file_data: FileData) -> Result<ExecStatus, ()> {
        if file_data.full_path.is_dir() {
            tokio::fs::remove_dir_all(&file_data.full_path).await
        } else {
            tokio::fs::remove_file(&file_data.full_path).await
        };
        Ok(ExecStatus::Done(TaskOutput::Empty))
    }
}

// Move to trash behavior
pub struct MoveToTrashBehavior;

impl DeleteBehavior for MoveToTrashBehavior {
    async fn delete_all<I>(files: I, interrupter: Option<&Interrupter>) -> Result<ExecStatus, ()>
    where
        I: IntoIterator<Item = FileData> + Send + 'static,
        I::IntoIter: Send + 'static,
    {
        if let Some(interrupter) = interrupter {
            check_interruption!(interrupter);
        }
        task::spawn_blocking(|| trash::delete_all(files.into_iter().map(|x| x.full_path))).await;
        Ok(ExecStatus::Done(().into()))
    }
}
```

### 6. Create Task Implementation

Define the task that will perform the actual work:

```rust
pub struct RemoveTask<B> {
    id: TaskId,
    files: Vec<FileData>,
    counter: Arc<AtomicU64>,
    behavior: PhantomData<fn(B) -> B>,
}

#[async_trait::async_trait]
impl<B: DeleteBehavior + Send + 'static> Task<Error> for RemoveTask<B> {
    fn id(&self) -> TaskId {
        self.id
    }

    async fn run(&mut self, interrupter: &Interrupter) -> Result<ExecStatus, Error> {
        let size = self.files.len();

        match B::delete_all(self.files.clone(), Some(interrupter)).await {
            Ok(ExecStatus::Done(_)) => {
                self.counter.fetch_add(size as _, Ordering::AcqRel);
                Ok(ExecStatus::Done(().into()))
            }
            Ok(status) => Ok(status),
            Err(_) => Err(Error::Deleter("Task failed".into()))
        }
    }
}
```

### 7. Implement Performance Optimizations

For jobs that handle large numbers of files or large file sizes, consider implementing these optimizations:

#### Batching

Group related operations into batches for better performance:

```rust
pub struct BatchedCopy {
    pub sources: Vec<PathBuf>,
    pub targets: Vec<PathBuf>,
    pub total_size: u64,
}

pub async fn batch_copy_files(
    files: Vec<(PathBuf, PathBuf)>,
) -> Result<Vec<BatchedCopy>, JobError> {
    const MAX_TOTAL_SIZE_PER_STEP: u64 = 1024 * 1024 * 800; // 800MB
    const MAX_FILES_PER_STEP: usize = 20;

    let mut batches = Vec::new();
    let mut current_batch = BatchedCopy {
        sources: Vec::new(),
        targets: Vec::new(),
        total_size: 0,
    };

    for (source, target) in files {
        // Create new batch if current one exceeds limits
        if current_batch.sources.len() >= MAX_FILES_PER_STEP
            || current_batch.total_size > MAX_TOTAL_SIZE_PER_STEP
        {
            batches.push(current_batch);
            current_batch = BatchedCopy::default();
        }

        current_batch.sources.push(source);
        current_batch.targets.push(target);
    }

    Ok(batches)
}
```

#### Conflict Resolution

Handle naming conflicts efficiently using a HashSet to track used names:

```rust
pub async fn resolve_name_conflicts(
    files: Vec<(PathBuf, PathBuf)>,
) -> Result<Vec<(PathBuf, PathBuf)>, JobError> {
    let mut seen_paths = HashSet::new();
    let mut resolved = Vec::with_capacity(files.len());

    for (source, target) in files {
        let mut final_target = target.clone();

        // If we've seen this path before or if it exists on disk
        if seen_paths.contains(&target) || target.exists() {
            final_target = find_available_name(&target).await?;
        }

        seen_paths.insert(final_target.clone());
        resolved.push((source, final_target));
    }

    Ok(resolved)
}
```

#### Adaptive Behaviors

Implement different strategies based on file characteristics:

```rust
pub trait CopyBehavior: Send + Sync {
    async fn copy_file(
        &self,
        source: impl AsRef<Path>,
        target: impl AsRef<Path>,
        ctx: &impl JobContext,
    ) -> Result<(), JobError>;

    fn is_suitable(
        &self,
        file_size: u64,
        source_fs: &str,
        target_fs: &str,
    ) -> bool;
}

// Fast copy for small files or same filesystem
pub struct FastCopyBehavior;

// Streaming copy for large files or cross-filesystem
pub struct StreamCopyBehavior {
    buffer_size: usize,
    retry_count: u32,
}

pub fn determine_behavior(
    source: impl AsRef<Path>,
    target: impl AsRef<Path>,
) -> Box<dyn CopyBehavior> {
    // Choose appropriate behavior based on file size and filesystem
    if file_size < FAST_COPY_THRESHOLD && same_filesystem(source, target) {
        Box::new(FastCopyBehavior)
    } else {
        Box::new(StreamCopyBehavior::new())
    }
}
```

### 8. Progress Reporting

Implement detailed progress tracking for better user feedback:

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CopyProgress {
    Started {
        total_files: u64,
        total_bytes: u64,
    },
    File {
        name: String,
        current_file: u64,
        total_files: u64,
        bytes: u64,
        source: PathBuf,
        target: PathBuf,
    },
    BytesWritten {
        bytes: u64,
        speed: f64,  // bytes per second
    },
    Complete {
        files_copied: u64,
        total_bytes: u64,
        duration: Duration,
    }
}

impl Task for CopyTask {
    async fn run(&mut self, ctx: &impl JobContext) -> Result<TaskStatus, JobError> {
        ctx.progress(CopyProgress::Started {
            total_files,
            total_bytes,
        }).await;

        for (idx, file) in files.iter().enumerate() {
            ctx.progress(CopyProgress::File {
                name: file.name.clone(),
                current_file: idx as u64 + 1,
                total_files,
                bytes: file.size,
                source: file.source.clone(),
                target: file.target.clone(),
            }).await;

            // Copy file and report progress...
        }

        ctx.progress(CopyProgress::Complete {
            files_copied,
            total_bytes,
            duration: start.elapsed(),
        }).await;

        Ok(TaskStatus::Completed)
    }
}
```

### 9. Implement Job Traits

Implement the required traits for your job:

```rust
impl<B: DeleteBehavior + Hash + Send + 'static> Job for DeleterJob<B> {
    const NAME: JobName = JobName::Delete;

    async fn run<OuterCtx: OuterContext>(
        mut self,
        dispatcher: JobTaskDispatcher,
        ctx: impl JobContext<OuterCtx>,
    ) -> Result<ReturnStatus, Error> {
        // Get required data
        let files = get_many_files_datas(ctx.db(), location_path, &self.file_path_ids).await?;

        // Create and dispatch tasks
        let counter = Arc::new(AtomicU64::new(0));
        let task = RemoveTask::new(files, counter.clone());
        let task_handle = dispatcher.dispatch(task)?;

        // Monitor progress
        while let Some(status) = task_handle.status().await {
            match status {
                TaskStatus::Running => {
                    let progress = counter.load(Ordering::Relaxed);
                    ctx.progress(ProgressUpdate::CompletedTaskCount(progress)).await;
                }
                TaskStatus::Completed => break,
                TaskStatus::Failed(e) => return Err(e),
                _ => continue,
            }
        }

        Ok(ReturnStatus::Completed(JobReturn::default()))
    }
}
```

### 10. Implement Serialization

Add serialization support for job persistence:

```rust
impl<OuterCtx, B> SerializableJob<OuterCtx> for DeleterJob<B>
where
    OuterCtx: OuterContext,
    B: DeleteBehavior + Hash + Send + 'static,
{
    fn serialize(mut self) -> Result<Option<Vec<u8>>, rmp_serde::encode::Error> {
        let state = DeleterState {
            location_id: self.location_id,
            file_path_ids: self.file_path_ids,
            shutdown_tasks: self.shutdown_tasks.map(|tasks|
                tasks.into_iter()
                    .filter_map(|t| t.serialize().ok())
                    .collect()),
            accumulative_errors: self.accumulative_errors,
        };

        Ok(Some(rmp_serde::to_vec(&state)?))
    }

    fn deserialize(
        serialized_job: &[u8],
        _: &OuterCtx,
    ) -> Result<Option<(Self, Option<SerializedTasks>)>, rmp_serde::decode::Error> {
        let state: DeleterState = rmp_serde::from_slice(serialized_job)?;

        Ok(Some((
            Self {
                location_id: state.location_id,
                file_path_ids: state.file_path_ids,
                pending_tasks: None,
                shutdown_tasks: None,
                accumulative_errors: state.accumulative_errors,
                behavior: PhantomData,
            },
            state.shutdown_tasks,
        )))
    }
}
```

## Directory Structure

When implementing a new job, follow this recommended directory structure based on the file-actions crate:

```
src/
├── your_job/
│   ├── mod.rs              # Public exports and job registration
│   ├── job.rs              # Job implementation and state management
│   ├── progress.rs         # Progress tracking types
│   └── tasks/
│       ├── mod.rs          # Task exports and shared types
│       ├── behaviors/      # Different implementation strategies
│       │   ├── mod.rs      # Behavior trait and utilities
│       │   ├── fast.rs     # Fast implementation (e.g., for small files)
│       │   └── stream.rs   # Streaming implementation (e.g., for large files)
│       ├── batch.rs        # Batch processing logic
│       ├── conflict.rs     # Conflict resolution utilities
│       └── task_name.rs    # Individual task implementations
```

### Key Components

1. **mod.rs**
   - Public exports for your job module
   - Re-exports of commonly used types
   ```rust
   mod job;
   mod progress;
   mod tasks;

   pub use job::YourJob;
   pub use progress::JobProgress;
   pub use tasks::{TaskBehavior, FastBehavior, StreamBehavior};
   ```

2. **job.rs**
   - Job struct and implementation
   - State management
   - Task coordination
   ```rust
   pub struct YourJob<C> {
       // Job parameters
       params: JobParams,
       // Task management
       pending_tasks: Option<Vec<TaskHandle>>,
       // Error handling
       accumulative_errors: Option<Vec<JobError>>,
   }
   ```

3. **progress.rs**
   - Progress tracking enums/structs
   - Progress calculation utilities
   ```rust
   #[derive(Debug, Clone, Serialize, Deserialize)]
   pub enum JobProgress {
       Started { total: u64 },
       Processing { completed: u64, total: u64 },
       Complete { total_processed: u64 },
   }
   ```

4. **tasks/behaviors/**
   - Trait defining behavior interface
   - Different implementation strategies
   ```rust
   #[async_trait]
   pub trait TaskBehavior {
       async fn execute(&self, params: Params) -> Result<(), JobError>;
       fn is_suitable(&self, params: &Params) -> bool;
   }
   ```

5. **tasks/batch.rs**
   - Batch processing logic
   - Performance optimizations
   ```rust
   pub struct BatchedOperation {
       items: Vec<Item>,
       total_size: u64,
   }
   ```

6. **tasks/conflict.rs**
   - Conflict resolution utilities
   - Name generation
   ```rust
   pub async fn resolve_conflicts(
       items: Vec<Item>
   ) -> Result<Vec<Item>, JobError>
   ```

This structure provides:
- Clear separation of concerns
- Easy navigation of code
- Consistent organization across jobs
- Scalability for complex operations
- Reusable components

When adding new jobs, mirror this structure to maintain consistency across the codebase.

## Best Practices

1. **Error Handling**

   - Use accumulative errors for non-critical failures
   - Include context in error messages
   - Handle cleanup on errors

2. **Progress Reporting**

   - Report progress regularly using `ctx.progress()`
   - Include meaningful progress messages
   - Use atomic counters for thread-safe progress tracking

3. **Resource Management**

   - Clean up resources on cancellation
   - Use `Arc` for shared resources
   - Implement proper task cleanup

4. **State Management**
   - Keep serialized state minimal
   - Handle state restoration properly
   - Use `Option` for non-persistent state

### Best Practices for Progress Reporting

#### Use Structured Data

Always send structured data instead of formatted strings. This allows the frontend to handle localization and formatting:

❌ Don't do this:

```rust
ctx.progress(ProgressUpdate::Message(format!(
    "Processed {} of {} items",
    completed,
    total
))).await;
```

✅ Do this instead:

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum JobProgress {
    Processing {
        completed: u64,
        total: u64,
        bytes_processed: u64,
        current_item: Option<String>,
    },
    Complete {
        total_processed: u64,
        total_bytes: u64,
        duration: Duration,
    }
}

// In your task:
ctx.progress(JobProgress::Processing {
    completed: files_processed,
    total: total_files,
    bytes_processed,
    current_item: Some(current_file.name.clone()),
}).await;
```

#### Include All Necessary Data

Progress updates should include enough information for the UI to show:

- Overall progress (e.g., files processed / total files)
- Current operation details (e.g., current file name, size)
- Performance metrics (e.g., speed, estimated time remaining)
- Operation-specific details (e.g., copy source/target)

#### Progress Granularity

Report progress at appropriate intervals:

- Major state changes (Started, Complete)
- Per-item updates for user feedback
- Periodic updates for long-running operations

Example of a well-structured progress enum:

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CopyProgress {
    Started {
        total_files: u64,
        total_bytes: u64,
    },
    File {
        name: String,
        current_file: u64,
        total_files: u64,
        bytes: u64,
        source: PathBuf,
        target: PathBuf,
    },
    BytesWritten {
        bytes: u64,
        speed: f64,
        eta_seconds: u32,
    },
    Complete {
        files_copied: u64,
        total_bytes: u64,
        duration: Duration,
    },
}
```

This approach:

- Enables proper i18n/l10n in the UI
- Provides flexibility in how data is displayed
- Makes it easier to modify the UI without backend changes
- Ensures consistent progress reporting across different locales

## Common Patterns

1. **Batch Processing**

```rust
let batch_size = 100;
for chunk in items.chunks(batch_size) {
    let task = MyTask::new(chunk.to_vec(), progress_counter.clone());
    tasks.push(dispatcher.dispatch(task)?);
}
```

2. **Error Accumulation**

```rust
if let Err(e) = result {
    self.accumulative_errors.get_or_insert(Vec::new()).push(e);
}
```

## Debugging Tips

1. Use tracing for better debugging:

```rust
tracing::debug!(task_id = %self.id, "Starting task execution");
```

2. Monitor task states:

```rust
while let Some(status) = task_handle.status().await {
    match status {
        TaskStatus::Running => continue,
        TaskStatus::Paused => handle_pause(),
        TaskStatus::Completed => break,
        TaskStatus::Failed(e) => handle_error(e),
    }
}
```

3. Add proper error context:

```rust
Error::TaskFailed(format!("Failed to process item {}: {}", item_id, e))
```

These optimizations help ensure your job:

- Handles large operations efficiently through batching
- Resolves conflicts reliably
- Adapts to different scenarios
- Provides detailed progress feedback
